{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "solution.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgyXdIMsmrAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "2deb61c8-d770-451b-f87f-08d3ea73df6a"
      },
      "source": [
        "!pip install -U tensorflow keras"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.7)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.9.11)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "E18tTiDZmfP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras import models, layers, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xN2MhJZumfRQ",
        "colab_type": "text"
      },
      "source": [
        "# A SF Permits Cleaning\n",
        "\n",
        "### Methode um Y/NaN Spalten zu konvertieren"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "Ng0A0DrhmfRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_y_with_0_1(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Ersetzt Y und leere Felder in Spalten die nur Y und leere Felder erhalten durch 1 und 0 \n",
        "    :param df: Dataframe in dem sich die Spalten befinden\n",
        "    :param column: Name der Spalte in der die Werte ersetzt werden sollen\n",
        "    :return: DataFrame mit modifizierten Spalten\n",
        "    \"\"\"\n",
        "    df[column].fillna(0, inplace=True)\n",
        "    df[column].replace('Y', 1, inplace=True)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KDqipAf6mfRq",
        "colab_type": "text"
      },
      "source": [
        "### Datenset laden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "PXvjYpcOmfRt",
        "colab_type": "code",
        "colab": {},
        "outputId": "38c31f83-7f01-476a-d748-7c0e2f923fdb"
      },
      "source": [
        "permits_df = pd.read_csv(\"building_permits.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\d074009\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (22,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "SgiwEGGOmfR8",
        "colab_type": "text"
      },
      "source": [
        "# B SF Permits Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uECrkdTMmfSy",
        "colab_type": "text"
      },
      "source": [
        "# C SF Permits Prediction\n",
        "\n",
        "### Methode für One-Hot-Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "gEvneBmXmfS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Erzeugt Dummy-Spalten für jeden Wert in der Quell-Spalte.\n",
        "    \n",
        "    Beispiel:\n",
        "    Wenn eine Tabelle die Spalte 'Klasse' mit 0, 1, 2 als Werte hat, werden die Spalte Klasse 0, Klasse 1 und Klasse 2\n",
        "    erstellt und die Zeilen der Tabelle an den entsprechenden Stellen auf 0 bzw. 1 gesetzt. \n",
        "    :param df: Dataframe in dem die zu ersetzende Spalte ist\n",
        "    :param col: Spalte die One-Hot-Encoded werden soll\n",
        "    :return: modifizierter DataFrame\n",
        "    \"\"\"\n",
        "    return df.assign(**{str(col + \" \" + str(val)): [1 if str(val) in str(cell) else 0 for cell in df[col]] \n",
        "                                   for val in df[col].unique()})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8cteI2CSmfTQ",
        "colab_type": "text"
      },
      "source": [
        "# D SF Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qq4hg4ZEmfTU",
        "colab_type": "text"
      },
      "source": [
        "# E Neural Networks XOR\n",
        "\n",
        "![XOR Graph](https://github.com/maxmoehl/ATIT2_assignments/blob/max/Assignment_2/XOR.png?raw=1)\n",
        "\n",
        "w: weight  \n",
        "b: bias  \n",
        "t: threshold\n",
        "\n",
        "Mathematische Funktion:\n",
        "```\n",
        "SIGMOID(x) = 1 / (1 + e^(-x))\n",
        "AND(x, y) = SIGMOID(50x + 50y - 75)\n",
        "OR(x, y) = SIGMOID(50x + 50y - 25)\n",
        "NOT(x) = SIGMOID(-50x + 10)\n",
        "\n",
        "XOR(x, y) = AND(NOT(AND(x, y)), OR(x, y))\n",
        "\n",
        "XOR(x,y) = SIGMOID(SIGMOID(SIGMOID(50x + 50y - 75) * (-50) + 10) * 50 + SIGMOID(50x + 50y - 25) * 50 - 75)\n",
        "           \\       \\       \\---------AND---------/             /        \\                     /          /\n",
        "            \\       \\-------------------NOT-------------------/          \\--------OR---------/          /\n",
        "             \\-------------------------------------------AND-------------------------------------------/\n",
        "```\n",
        "\n",
        "### Funktionen in Python abbilden und testen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "1TTHzLkbmfTn",
        "colab_type": "code",
        "colab": {},
        "outputId": "a6b47881-b4b4-4098-8e62-0b7accfe3b6a"
      },
      "source": [
        "def SIGMOID(x):\n",
        "    return 1 / (1 + (math.e ** (-x)))\n",
        "\n",
        "def AND(x, y):\n",
        "    return SIGMOID(x * 50 + y * 50 - 75)\n",
        "\n",
        "def OR(x, y):\n",
        "    return SIGMOID(x * 50 + y * 50 - 25)\n",
        "    \n",
        "def NOT(x):\n",
        "    return SIGMOID(x * (-50) + 10)\n",
        "\n",
        "def XOR(x, y):\n",
        "    return AND(NOT(AND(x, y)),OR(x, y))\n",
        "\n",
        "print(round(XOR(0, 0), 10))\n",
        "print(round(XOR(0, 1), 10))\n",
        "print(round(XOR(1, 0), 10))\n",
        "print(round(XOR(1, 1), 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n",
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eDlLEWzbmfUI",
        "colab_type": "text"
      },
      "source": [
        "# F Neural Networks Overfitting\n",
        "\n",
        "### Daten Laden und splitten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "M_yT5hcrmfUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_test, Y_test), (X_train, Y_train) = datasets.cifar10.load_data()\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Ct-YymVMmfUh",
        "colab_type": "text"
      },
      "source": [
        "### Modell erstellen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "x-SNE32hmfUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "77113798-fd59-438c-c52c-82f8083c1208"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_28 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8JZFmi49mfUz",
        "colab_type": "text"
      },
      "source": [
        "### Modell in 40 Epochen trainieren und jede Epoche die Genauigkeit messen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "GBTYy98WmfU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92b1bee0-4edc-4643-bed0-a9d876376559"
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=100, epochs=40, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 50000 samples\n",
            "Epoch 1/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 2.0086 - accuracy: 0.2564 - val_loss: 1.8344 - val_accuracy: 0.3312\n",
            "Epoch 2/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.6770 - accuracy: 0.3811 - val_loss: 1.5995 - val_accuracy: 0.4099\n",
            "Epoch 3/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.5259 - accuracy: 0.4419 - val_loss: 1.5393 - val_accuracy: 0.4351\n",
            "Epoch 4/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.4227 - accuracy: 0.4835 - val_loss: 1.4385 - val_accuracy: 0.4751\n",
            "Epoch 5/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.3291 - accuracy: 0.5260 - val_loss: 1.3763 - val_accuracy: 0.5066\n",
            "Epoch 6/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.2523 - accuracy: 0.5491 - val_loss: 1.3935 - val_accuracy: 0.4941\n",
            "Epoch 7/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.2248 - accuracy: 0.5556 - val_loss: 1.2780 - val_accuracy: 0.5467\n",
            "Epoch 8/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.1440 - accuracy: 0.5918 - val_loss: 1.3183 - val_accuracy: 0.5375\n",
            "Epoch 9/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.1166 - accuracy: 0.6015 - val_loss: 1.2111 - val_accuracy: 0.5719\n",
            "Epoch 10/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.0627 - accuracy: 0.6204 - val_loss: 1.2468 - val_accuracy: 0.5641\n",
            "Epoch 11/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.0134 - accuracy: 0.6392 - val_loss: 1.1940 - val_accuracy: 0.5759\n",
            "Epoch 12/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.9883 - accuracy: 0.6494 - val_loss: 1.1896 - val_accuracy: 0.5863\n",
            "Epoch 13/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.9232 - accuracy: 0.6681 - val_loss: 1.1764 - val_accuracy: 0.5917\n",
            "Epoch 14/40\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.8755 - accuracy: 0.6853 - val_loss: 1.1522 - val_accuracy: 0.6008\n",
            "Epoch 15/40\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 0.8397 - accuracy: 0.7059 - val_loss: 1.1395 - val_accuracy: 0.6053\n",
            "Epoch 16/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.8100 - accuracy: 0.7176 - val_loss: 1.1614 - val_accuracy: 0.6002\n",
            "Epoch 17/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.7753 - accuracy: 0.7308 - val_loss: 1.1953 - val_accuracy: 0.5936\n",
            "Epoch 18/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.7367 - accuracy: 0.7397 - val_loss: 1.2007 - val_accuracy: 0.6013\n",
            "Epoch 19/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.6932 - accuracy: 0.7595 - val_loss: 1.1938 - val_accuracy: 0.6080\n",
            "Epoch 20/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.6651 - accuracy: 0.7720 - val_loss: 1.1921 - val_accuracy: 0.6121\n",
            "Epoch 21/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.6366 - accuracy: 0.7751 - val_loss: 1.2406 - val_accuracy: 0.6032\n",
            "Epoch 22/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.6013 - accuracy: 0.7880 - val_loss: 1.2205 - val_accuracy: 0.6082\n",
            "Epoch 23/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.5439 - accuracy: 0.8128 - val_loss: 1.2851 - val_accuracy: 0.6024\n",
            "Epoch 24/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.5302 - accuracy: 0.8148 - val_loss: 1.2418 - val_accuracy: 0.6149\n",
            "Epoch 25/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.4746 - accuracy: 0.8385 - val_loss: 1.3006 - val_accuracy: 0.6141\n",
            "Epoch 26/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.4475 - accuracy: 0.8481 - val_loss: 1.3985 - val_accuracy: 0.6060\n",
            "Epoch 27/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.4517 - accuracy: 0.8396 - val_loss: 1.3903 - val_accuracy: 0.6069\n",
            "Epoch 28/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.3868 - accuracy: 0.8674 - val_loss: 1.4289 - val_accuracy: 0.6088\n",
            "Epoch 29/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.3763 - accuracy: 0.8743 - val_loss: 1.4441 - val_accuracy: 0.6160\n",
            "Epoch 30/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.3255 - accuracy: 0.8945 - val_loss: 1.4716 - val_accuracy: 0.6051\n",
            "Epoch 31/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.3064 - accuracy: 0.8984 - val_loss: 1.5635 - val_accuracy: 0.6077\n",
            "Epoch 32/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.2761 - accuracy: 0.9117 - val_loss: 1.6585 - val_accuracy: 0.6034\n",
            "Epoch 33/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.2458 - accuracy: 0.9237 - val_loss: 1.6777 - val_accuracy: 0.6092\n",
            "Epoch 34/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.2282 - accuracy: 0.9282 - val_loss: 1.6983 - val_accuracy: 0.6037\n",
            "Epoch 35/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.1922 - accuracy: 0.9433 - val_loss: 1.8104 - val_accuracy: 0.6013\n",
            "Epoch 36/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.1857 - accuracy: 0.9420 - val_loss: 1.8267 - val_accuracy: 0.6001\n",
            "Epoch 37/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.1441 - accuracy: 0.9613 - val_loss: 1.9321 - val_accuracy: 0.5988\n",
            "Epoch 38/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.1520 - accuracy: 0.9533 - val_loss: 1.9695 - val_accuracy: 0.6023\n",
            "Epoch 39/40\n",
            "10000/10000 [==============================] - 34s 3ms/step - loss: 0.1238 - accuracy: 0.9641 - val_loss: 2.0910 - val_accuracy: 0.5939\n",
            "Epoch 40/40\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 0.1003 - accuracy: 0.9748 - val_loss: 2.1452 - val_accuracy: 0.5997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "j91wYUKSmfVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "37d56dfd-9611-465a-dc90-34ae62cdb25e"
      },
      "source": [
        "def plot_results(history, epoch_lim=40):\n",
        "  plt.plot(history.history['loss'], label='train')\n",
        "  plt.plot(history.history['val_loss'], label='test')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.ylim([0, 2.5])\n",
        "  plt.xlim([0, epoch_lim])\n",
        "  plt.legend(loc='upper left')\n",
        "\n",
        "plot_results(history)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "QvoaEtspmfVq",
        "colab_type": "text"
      },
      "source": [
        "Die Genauigkeit der Vorhersage von Labels des Trainings-Sets erhöht sich kontinuierlich aber die Genauigkeit bei den\n",
        "Test-Daten steigt auf ca 72% an und fällt dann aber wieder auf 69% ab. Das Modell lernt die Bilder aus dem\n",
        "Trainings-Set auswendig und kann deswegen keine guten Vorhersagen für das Test-Set machen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lKmfzO1ImfVs",
        "colab_type": "text"
      },
      "source": [
        "# G Neural Networks Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4zsJTxnn2iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = datasets.cifar10.load_data()\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "num_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlyA-wrxspiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "a7ba96b9-ec2e-45a8-f293-3d9670138ad8"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_22 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbmV_PDjns8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d66b361f-b4bb-42b0-dfa3-4a447e98082e"
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=100, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 1.6506 - accuracy: 0.3944 - val_loss: 1.4211 - val_accuracy: 0.4778\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 1.3139 - accuracy: 0.5287 - val_loss: 1.2233 - val_accuracy: 0.5646\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 1.1548 - accuracy: 0.5917 - val_loss: 1.1593 - val_accuracy: 0.5869\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 1.0563 - accuracy: 0.6285 - val_loss: 1.0736 - val_accuracy: 0.6243\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 0.9755 - accuracy: 0.6590 - val_loss: 0.9868 - val_accuracy: 0.6516\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 0.9149 - accuracy: 0.6799 - val_loss: 0.9505 - val_accuracy: 0.6689\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 0.8636 - accuracy: 0.6993 - val_loss: 0.9176 - val_accuracy: 0.6798\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 0.8245 - accuracy: 0.7110 - val_loss: 0.9217 - val_accuracy: 0.6808\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 0.7861 - accuracy: 0.7280 - val_loss: 0.9306 - val_accuracy: 0.6831\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 71s 1ms/step - loss: 0.7539 - accuracy: 0.7383 - val_loss: 0.8904 - val_accuracy: 0.6900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Thc13BsySn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "c887ecd0-6d33-4758-eafe-f4debb4d1c4a"
      },
      "source": [
        "plot_results(history, epoch_lim=10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "c9nEz-InmfV2",
        "colab_type": "text"
      },
      "source": [
        "# H Feedback"
      ]
    }
  ]
}